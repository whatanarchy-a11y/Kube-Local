# k8s 초급자 트러블슈팅 (k3s + Traefik 실습 기준)

> 구성:  
> 1) **1장 체크리스트(명령어 15개)**  
> 2) **장애 유형별 예시 출력 + 해석 + 해결**  
> 3) **실습용 트러블 시나리오 10개 문제집(망가뜨리기/복구)**

---

## 1) 명령어 15개로 끝내는 트러블슈팅 1장 체크리스트 (k3s/Traefik)

### 0) 내가 지금 어느 클러스터/네임스페이스?
1) 컨텍스트/기본 ns
```bash
kubectl config current-context
kubectl config view --minify
```

2) 전체에서 찾기(“어디에 만들었지?”)
```bash
kubectl get all -A | grep -i <name>
```

---

## A. Pod가 이상하다 (Pending/CrashLoop/ImagePull/Running인데 서비스 안됨)

3) Pod 상태 빠르게 보기
```bash
kubectl get pod -A -o wide
```

4) Pod 원인 1순위(Events 포함)
```bash
kubectl describe pod <pod> -n <ns>
```

5) 로그(CrashLoop이면 필수)
```bash
kubectl logs <pod> -n <ns> --tail=200
kubectl logs <pod> -n <ns> --previous --tail=200
```

6) 이벤트 “최신순” (대부분 여기서 답 나옴)
```bash
kubectl get events -n <ns> --sort-by=.lastTimestamp | tail -n 30
```

7) 노드/리소스 부족 확인(Pending에서 자주)
```bash
kubectl get nodes -o wide
kubectl top nodes
```

---

## B. Service가 안 붙는다 (selector/port/endpoints/DNS)

8) Service/포트/타입 확인
```bash
kubectl get svc -n <ns> -o wide
kubectl describe svc <svc> -n <ns>
```

9) 엔드포인트(없으면 selector 라벨부터 의심)
```bash
kubectl get endpoints <svc> -n <ns> -o yaml
kubectl get pod -n <ns> --show-labels
```

10) 클러스터 내부에서 서비스 테스트(가장 확실)
```bash
kubectl -n <ns> run dns --rm -it --restart=Never --image=busybox:1.36 -- sh
# inside:
nslookup <svc>
nslookup <svc>.<ns>.svc.cluster.local
wget -qO- http://<svc>.<ns>.svc.cluster.local:<port>/
```

---

## C. Ingress / Traefik이 이상하다 (404/라우팅/호스트)

11) Ingress 전체 확인
```bash
kubectl get ingress -A
kubectl describe ingress <ing> -n <ns>
```

12) Traefik 상태/로그
```bash
kubectl -n kube-system get pods | grep -i traefik
kubectl -n kube-system logs deploy/traefik --tail=200
```

13) (k3s에서 가끔) LoadBalancer처럼 보이는 svclb 확인
```bash
kubectl -n kube-system get pods | grep -i svclb
kubectl -n kube-system describe pod <svclb-pod>
```

---

## D. “내가 들어간 셸이 컨테이너인지?” 확인

14) 컨테이너 셸에서 확인
```sh
hostname
ip a
cat /proc/1/cgroup | head
```
- 보통 **hostname이 pod처럼 보이고**, 네트워크가 **10.42.x** 대역이면 컨테이너일 확률이 큼

---

## E. 노드 유지보수(drain)에서 막힘

15) DaemonSet 때문에 drain 막힐 때(실습용)
```bash
kubectl drain <node> --ignore-daemonsets --delete-emptydir-data
```

---

### “증상 → 바로 쓰는 조합” 초단축 맵
- **Pending** → `describe pod` + `top nodes` + `describe node`
- **CrashLoopBackOff** → `logs --previous` + `describe pod`
- **ImagePullBackOff** → `describe pod (Events)` + 이미지명/레지스트리/시크릿
- **서비스 접속 안됨** → `describe svc` + `endpoints` + `pod labels` + 내부 busybox 테스트
- **Ingress 404** → `describe ingress` + `traefik logs`

---

## 2) 장애 유형별 예시 출력 + 해석 + 해결 (샘플)

### 2-1) Pod `Pending` (스케줄링 실패)
**예시**
```bash
kubectl get pod -n demo -o wide
NAME                  READY   STATUS    NODE
web-7c7b8c9d8-9xk2m   0/1     Pending   <none>
```

```bash
kubectl describe pod web-7c7b8c9d8-9xk2m -n demo
...
Events:
  Warning  FailedScheduling   0/3 nodes are available: 3 Insufficient cpu.
```

**해석 포인트**
- `NODE <none>` + `FailedScheduling` → **스케줄러가 배치 못함**
- `Insufficient cpu/memory` → **리소스 부족**

**해결**
```bash
kubectl top nodes
kubectl top pod -A | head
```

---

### 2-2) `ImagePullBackOff` (이미지 다운로드 실패)
**예시**
```bash
kubectl describe pod api-... -n demo
...
Events:
  Normal   Pulling    Pulling image "ngnix:1.27"
  Warning  Failed     Failed to pull image "ngnix:1.27": not found
  Warning  BackOff    Back-off pulling image "ngnix:1.27"
```

**해석 포인트**
- `not found` → **오타/태그 없음**
- `unauthorized`면 → **사설 레지스트리 인증 문제**

**해결**
- 이미지명/태그 수정
- 사설 레지스트리면 `imagePullSecrets` 구성

---

### 2-3) `CrashLoopBackOff` (컨테이너가 계속 죽음)
**예시**
```bash
kubectl get pod -n demo
NAME      READY   STATUS             RESTARTS
web-...   0/1     CrashLoopBackOff   5
```

```bash
kubectl logs web-... -n demo --previous --tail=50
Error: listen tcp :8080: bind: address already in use
```

**해석 포인트**
- **제일 먼저 `logs --previous`** 봐야 “죽기 직전 로그”가 나옴
- 흔한 원인: 포트 충돌, ENV 누락, 설정 파일 경로 오류, 프로브 실패

**해결**
- 앱 실행 옵션/환경변수/포트 점검
- 프로브 완화(초기지연 증가, 실패 임계치 조정)

---

### 2-4) `Running`인데 서비스 접속 불가 (Service selector/port/endpoints)
**예시**
```bash
kubectl get pod -n demo --show-labels
web-...  Running  app=web

kubectl describe svc web-svc -n demo
Selector: app=weeb

kubectl get endpoints web-svc -n demo
ENDPOINTS: <none>
```

**해석 포인트**
- Endpoints `<none>` = **Service가 연결할 Pod를 못 찾음**
- 대부분 **selector 라벨 오타**

**해결**
```bash
kubectl edit svc web-svc -n demo
# selector를 app=web로 수정
```

---

### 2-5) DNS 조회에서 NXDOMAIN이 섞여 나옴
**예시**
```sh
nslookup web-svc
** server can't find web-svc.svc.cluster.local: NXDOMAIN
Name: web-svc.demo.svc.cluster.local
Address: 10.43.31.179
```

**해석 포인트**
- 검색 도메인 순서에 따라 여러 후보를 시도하다 NXDOMAIN이 찍힐 수 있음
- 핵심은 **원하는 FQDN이 정상 해석되는지**

**해결**
```sh
nslookup web-svc.demo.svc.cluster.local
```

---

### 2-6) Ingress 404 / 라우팅 안 됨 (Traefik)
**예시(로그 힌트)**
```bash
kubectl -n kube-system logs deploy/traefik --tail=200
... msg="service not found" serviceName=whoami namespace=default
```

**해석 포인트**
- `service not found` → ingress backend 서비스명/namespace/port 불일치 가능성

**해결**
```bash
kubectl get svc -n <ns>
kubectl describe svc <svc> -n <ns>
kubectl describe ingress <ing> -n <ns>
```

---

### 2-7) `kubectl drain` 실패 (DaemonSet)
**예시**
```bash
kubectl drain w1
error: cannot delete DaemonSet-managed Pods ...
```

**해석 포인트**
- DaemonSet Pod는 노드 상주 목적 → 기본 drain이 삭제 못 함

**해결(실습용)**
```bash
kubectl drain w1 --ignore-daemonsets --delete-emptydir-data
```

---

### 2-8) “내가 지금 컨테이너 안 셸인가?”
**확인**
```sh
hostname
ip a
cat /proc/1/cgroup | head
```

---

## 3) 실습용 트러블 시나리오 10개 문제집 (망가뜨리기/복구)

### 사전 준비(공통)
네임스페이스 `demo` 기준.

```bash
kubectl create ns demo
```

기본 웹(nginx) + svc
```yaml
# 00-good.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
  namespace: demo
spec:
  replicas: 2
  selector:
    matchLabels: { app: web }
  template:
    metadata:
      labels: { app: web }
    spec:
      containers:
      - name: nginx
        image: nginx:1.27-alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: web-svc
  namespace: demo
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 80
```

```bash
kubectl apply -f 00-good.yaml
```

---

### 시나리오 1) Service selector 오타 → Endpoints 없음
**망가뜨리기**
```bash
kubectl -n demo patch svc web-svc -p '{"spec":{"selector":{"app":"weeb"}}}'
```

**증상**
```bash
kubectl -n demo get endpoints web-svc
# ENDPOINTS <none>
```

**고치기**
```bash
kubectl -n demo patch svc web-svc -p '{"spec":{"selector":{"app":"web"}}}'
```

---

### 시나리오 2) targetPort 틀림 → 연결은 되는데 접속 실패
**망가뜨리기**
```bash
kubectl -n demo patch svc web-svc -p '{"spec":{"ports":[{"port":80,"targetPort":81}]}}'
```

**확인(내부에서 테스트)**
```bash
kubectl -n demo run bb --rm -it --restart=Never --image=busybox:1.36 -- sh
# inside:
wget -qO- http://web-svc:80/
```

**고치기**
```bash
kubectl -n demo patch svc web-svc -p '{"spec":{"ports":[{"port":80,"targetPort":80}]}}'
```

---

### 시나리오 3) 네임스페이스 착각 → “없는 리소스”로 보임
**실수 유도**
```bash
kubectl get svc web-svc
# NotFound
```

**고치기**
```bash
kubectl -n demo get svc web-svc
kubectl get svc -A | grep web-svc
```

---

### 시나리오 4) ImagePullBackOff (이미지 오타)
**망가뜨리기**
```bash
kubectl -n demo set image deploy/web nginx=ngnix:1.27
```

**확인**
```bash
kubectl -n demo get pod
kubectl -n demo describe pod <pod> | sed -n '/Events/,$p'
```

**고치기**
```bash
kubectl -n demo set image deploy/web nginx=nginx:1.27-alpine
```

---

### 시나리오 5) CrashLoopBackOff (명령어로 강제 종료시키기)
**망가뜨리기**
```bash
kubectl -n demo patch deploy web --type='json' -p='[
{"op":"add","path":"/spec/template/spec/containers/0/command","value":["sh","-c","echo boom; exit 1"]}
]'
```

**확인**
```bash
kubectl -n demo get pod
kubectl -n demo logs <pod> --previous --tail=50
```

**고치기**
```bash
kubectl -n demo rollout undo deploy/web
```

---

### 시나리오 6) ReadinessProbe 실패 → Pod Running인데 READY 0/1
**망가뜨리기**
```bash
kubectl -n demo patch deploy web --type='json' -p='[
{"op":"add","path":"/spec/template/spec/containers/0/readinessProbe",
 "value":{"httpGet":{"path":"/not-exist","port":80},"initialDelaySeconds":3,"periodSeconds":5}}
]'
```

**확인**
```bash
kubectl -n demo get pod
kubectl -n demo describe pod <pod> | sed -n '/Readiness/,$p'
```

**고치기**
```bash
kubectl -n demo rollout undo deploy/web
```

---

### 시나리오 7) Pending (리소스 요청 과하게) → 스케줄링 실패
**망가뜨리기**
```bash
kubectl -n demo patch deploy web --type='json' -p='[
{"op":"add","path":"/spec/template/spec/containers/0/resources",
 "value":{"requests":{"cpu":"100","memory":"100Gi"}}}
]'
```

**확인**
```bash
kubectl -n demo get pod
kubectl -n demo describe pod <pod> | sed -n '/Events/,$p'
```

**고치기**
```bash
kubectl -n demo rollout undo deploy/web
```

---

### 시나리오 8) DNS/FQDN 헷갈림 → NXDOMAIN 혼란
**실수 유도**
```bash
kubectl -n default run bb --rm -it --restart=Never --image=busybox:1.36 -- sh
# inside:
nslookup web-svc
```

**정답(고치기)**
```sh
nslookup web-svc.demo.svc.cluster.local
```

---

### 시나리오 9) Ingress 404 (Host 헤더/호스트 룰 문제)
**Ingress 예시**
```yaml
# 09-ing.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-ing
  namespace: demo
spec:
  ingressClassName: traefik
  rules:
  - host: web.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-svc
            port:
              number: 80
```

**적용**
```bash
kubectl apply -f 09-ing.yaml
kubectl get ingress -n demo
```

**고치기(Host 헤더 포함 호출)**
```bash
curl -H "Host: web.local" http://<INGRESS_IP>/
```

---

### 시나리오 10) Ingress backend 서비스명 오타 → Traefik에 service not found
**망가뜨리기**
```bash
kubectl -n demo patch ingress web-ing --type='json' -p='[
{"op":"replace","path":"/spec/rules/0/http/paths/0/backend/service/name","value":"web-svcc"}
]'
```

**확인**
```bash
kubectl -n kube-system logs deploy/traefik --tail=200
kubectl -n demo describe ingress web-ing
```

**고치기**
```bash
kubectl -n demo patch ingress web-ing --type='json' -p='[
{"op":"replace","path":"/spec/rules/0/http/paths/0/backend/service/name","value":"web-svc"}
]'
```

---

## 4) 원인 즉시 판별 “3종 세트” (암기용)
```bash
kubectl describe pod <pod> -n <ns>
kubectl logs <pod> -n <ns> --previous --tail=200
kubectl get events -n <ns> --sort-by=.lastTimestamp | tail -n 30
```
