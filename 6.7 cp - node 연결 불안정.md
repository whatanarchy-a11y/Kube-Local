ubuntu@cp1:~$ kubectl get nodes -o wide
NAME   STATUS     ROLES           AGE    VERSION        INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
cp1    Ready      control-plane   4d4h   v1.34.3+k3s1   192.168.56.10   <none>        Ubuntu 22.04.5 LTS   5.15.0-164-generic   containerd://2.1.5-k3s1
w1     NotReady   <none>          4d4h   v1.34.3+k3s1   192.168.56.11   <none>        Ubuntu 22.04.5 LTS   5.15.0-164-generic   containerd://2.1.5-k3s1
w2     NotReady   <none>          4d4h   v1.34.3+k3s1   192.168.56.12   <none>        Ubuntu 22.04.5 LTS   5.15.0-164-generic   containerd://2.1.5-k3s1
w3     NotReady   <none>          33m    v1.34.3+k3s1   192.168.56.11   <none>        Ubuntu 22.04.5 LTS   5.15.0-164-generic   containerd://2.1.5-k3s1 w3 이 not ready 인데

좋아, 이 출력만 봐도 Pod가 안 뜨는 핵심 원인이 거의 확정이에요.

1) 현재 클러스터 상태 요약

스케줄링 가능한 Ready 노드가 사실상 cp1(컨트롤플레인) 1대뿐입니다.

w1 / w2 / w3는 전부 NotReady라서 워크로드(Pod)를 올릴 수 없어요.

2) 특히 w3는 더 심각한 힌트가 있어요

w3의 INTERNAL-IP가 192.168.56.11로 찍혀 있는데, 이건 w1의 IP와 동일합니다.

즉, 지금은 “노드가 죽어서 NotReady” 수준이 아니라,

노드 IP 충돌(중복 IP) 또는

같은 VM/네트워크 설정 복제(클론) 후 IP를 제대로 안 바꿈
때문에 클러스터가 노드를 정상 식별/통신 못해서 NotReady가 된 상황일 가능성이 매우 큽니다.

바로 해야 할 조치 (순서대로)
A) w3부터: IP 중복 해결

w3는 **반드시 192.168.56.13 같은 ‘유니크 IP’**로 바꿔야 합니다.
(지금처럼 w1과 같은 56.11이면 절대 Ready 못 됩니다.)

w3 VM에서:

IP 확인

ip a
ip r


netplan이면 /etc/netplan/*.yaml 확인 후 IP를 유니크하게 수정하고 적용

sudo cat /etc/netplan/*.yaml
sudo netplan apply


VirtualBox 쪽에서 “같은 MAC/같은 어댑터 설정 복제”가 발생해도 비슷한 문제가 납니다. MAC도 서로 달라야 안전합니다.

B) w1, w2, w3가 NotReady인 “직접 원인” 확인

각 워커(w1/w2/w3)에서 아래를 실행해서 k3s agent가 살아있는지부터 봐야 합니다.

워커 노드에서:

sudo systemctl status k3s-agent
sudo journalctl -u k3s-agent -n 200 --no-pager


자주 나오는 원인:

서버(cp1)로 연결 실패(토큰/주소/방화벽)

노드 IP/MAC 중복

time sync 문제

인증서/노드 등록 꼬임(클론 후 흔함)

C) “지금 당장” cp1 한 대에서라도 Pod 띄우고 싶다면 (실습용 임시)

cp1은 control-plane이라 기본 taint 때문에 일반 Pod가 안 올라갈 수 있어요.

확인:

kubectl describe node cp1 | egrep -n "Taints|Unschedulable|Roles"


taint가 있으면(대부분 있음) 실습에서는 제거해서 일단 띄울 수 있어요:

kubectl taint nodes cp1 node-role.kubernetes.io/control-plane:NoSchedule-
kubectl taint nodes cp1 node-role.kubernetes.io/master:NoSchedule-  # 있으면 이것도


그 다음 Deployment가 Pending이던 Pod를 cp1에 올릴 수 있습니다.

D) w3를 “새 노드로 추가”하려던 거면: w1/w2와 충돌 정리

지금 상태는 w1도 NotReady인데 w3가 w1 IP를 가져온 상태라, 둘 다 꼬일 수 있어요.
IP 수정 후에도 계속 이상하면, 가장 깔끔한 건:

w3에서 k3s-agent를 완전히 정리 후 재조인(join)

(토큰/서버 URL로 다시 agent 설치/등록)

다음 2개만 추가로 붙여줘 (원인 확정용)

cp1에서:

kubectl get pods -A -o wide | egrep "Pending|Terminating|CrashLoop|demo-hpa|kube-system" -n
kubectl -n demo-hpa get events --sort-by=.lastTimestamp | tail -n 50


w3에서:

ip a
sudo systemctl status k3s-agent
sudo journalctl -u k3s-agent -n 80 --no-pager


하지만 지금 단계에서 1순위 해결은 w3 IP 중복(56.11)부터 바로 잡는 것입니다.
그거 해결되면 Ready로 올라올 확률이 매우 높아요.

buntu@w3:~$ ip -br a
lo               UNKNOWN        127.0.0.1/8 ::1/128
enp0s3           UP             10.0.2.5/24 metric 100 fe80::a00:27ff:fe96:714e/64
enp0s8           UP             192.168.56.13/24 fe80::a00:27ff:febd:9735/64
flannel.1        UNKNOWN        10.42.0.0/32 fe80::445c:7dff:fe69:8b31/64
cni0             UP             10.42.0.1/24 fe80::44bc:c3ff:fe1a:b1c6/64
veth92a06b18@if2 UP             fe80::f02b:26ff:fe6b:6eda/64
veth346012fa@if2 UP             fe80::e006:54ff:feb5:b8a0/64
vethbf0a3f43@if2 UP             fe80::5425:bfff:feb5:d26e/64
vethd3f37f3e@if2 UP             fe80::44b8:9cff:fe83:8ba8/64
vetheb63361c@if2 UP             fe80::bcae:eeff:feff:6365/64
ubuntu@w3:~$ sudo cat /etc/netplan/*.yaml
# This file is generated from information provided by the datasource.  Changes
# to it will not persist across an instance reboot.  To disable cloud-init's
# network configuration capabilities, write a file
# /etc/cloud/cloud.cfg.d/99-disable-network-config.cfg with the following:
# network: {config: disabled}
network:
    ethernets:
        enp0s3:
            dhcp4: true
        enp0s8:
            dhcp4: no
            addresses: [192.168.56.13/24]
    version: 2
ubuntu@w3:~$

좋아. w3 자체는 IP가 정상(192.168.56.13) 이고 netplan도 그걸로 잡혀있네요.
그런데 cp1에서 kubectl get nodes는 w3의 INTERNAL-IP를 192.168.56.11로 잘못 보고 있어요.
이 조합이면 거의 확정적으로 **“노드 등록 정보가 꼬였거나(중복 등록), 기존 w1의 노드 아이덴티티를 w3가 가져온 상태”**입니다.

k3s에서 이건 보통 (1) /etc/hostname 또는 machine-id가 복제됨, (2) k3s-agent가 예전 노드 이름/인증서로 재조인 됨, (3) 같은 노드가 다른 IP로 바뀌었는데 상태가 꼬임… 이런 케이스예요.

아래 순서대로 “깨끗하게 w3를 재조인”하면 대부분 바로 풀립니다.

1) w3에서 “노드 식별자” 확인 (10초)
hostname
cat /etc/machine-id
cat /var/lib/dbus/machine-id 2>/dev/null
cat /etc/hostname


여기서 hostname이 w1이랑 같거나, machine-id가 w1과 같으면 100% 복제 문제입니다.

2) w3를 클러스터에서 완전히 제거 후 재조인 (가장 확실)
A) cp1에서 먼저 w3 노드 삭제
kubectl delete node w3


만약 w3 삭제가 안 되거나 꼬이면 w1도 같이 정리해야 할 수 있어요(아래 B 참고).

B) w3에서 k3s-agent 완전 초기화

w3에서:

sudo /usr/local/bin/k3s-agent-uninstall.sh
sudo rm -rf /etc/rancher /var/lib/rancher

C) (중요) hostname을 유니크하게 설정

w3에서:

sudo hostnamectl set-hostname w3

D) machine-id 재생성 (클론 VM이면 이게 핵심)

w3에서:

sudo rm -f /etc/machine-id /var/lib/dbus/machine-id
sudo systemd-machine-id-setup
sudo reboot

3) 재부팅 후 w3를 다시 join

재부팅 후 w3에서, cp1의 토큰으로 다시 agent 설치/실행합니다.

cp1에서 토큰 확인:

sudo cat /var/lib/rancher/k3s/server/node-token


w3에서(서버 IP는 cp1: 192.168.56.10):

curl -sfL https://get.k3s.io | K3S_URL=https://192.168.56.10:6443 K3S_TOKEN='<위 토큰>' sh -
sudo systemctl enable --now k3s-agent

4) cp1에서 확인
kubectl get nodes -o wide


여기서 w3가 Ready로 뜨고 INTERNAL-IP가 192.168.56.13으로 정확히 찍혀야 정상입니다.

5) (Pod가 cp1에만 남아서 안 뜨는 케이스도 같이 체크)

워커가 전부 NotReady면 Deployment Pod가 Pending이 되는데, 이유는 이벤트에 나옵니다:

kubectl -n demo-hpa get events --sort-by=.lastTimestamp | tail -n 50

한 줄 결론

지금은 w3 네트워크가 아니라 **“클러스터가 w3를 w1(192.168.56.11)로 착각하는 등록/아이덴티티 꼬임”**이에요.
위처럼 w3의 hostname + machine-id를 유니크하게 만든 뒤 k3s-agent를 깨끗하게 재조인하면 해결됩니다.

원하면 cp1에서 kubectl get nodes -o wide 최신 결과(지금 시점)랑, w3의 hostname 출력 한 줄만 더 붙여줘. 그걸로 “w1과 동일 아이덴티티”인지 바로 확정해줄게.